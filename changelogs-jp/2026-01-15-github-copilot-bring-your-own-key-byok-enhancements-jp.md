---
title: "GitHub Copilot bring your own key (BYOK) の機能強化"
date: "2026-01-15"
type: "new releases"
labels: ["copilot"]
author: "Allison"
source_url: "https://github.blog/changelog/2026-01-15-github-copilot-bring-your-own-key-byok-enhancements"
fetched_at: "2026-02-03T14:50:54.772309Z"
lang: "ja"
---

# GitHub Copilot bring your own key (BYOK) の機能強化

## Overview
GitHub Copilot の Bring your own key (BYOK) が、追加の API、新しい設定オプション、より多くのプロバイダー統合をサポートするようになりました。

## Detailed Explanation
### Overview
- GitHub Copilot の Bring your own key (BYOK) が、追加の API、新しい設定オプション、より多くのプロバイダー統合をサポートするようになりました。
- このアップデートにより、エンタープライズは Responses API を使用するモデルに接続し、モデルインタラクションの最大コンテキストウィンドウを設定し、ストリーミングを有効にし、拡張されたサポート対象 LLM プロバイダーのリストから選択できます。

### What's new
- 新しいプロバイダーオプション AWS Bedrock、Google AI Studio、およびあらゆる OpenAI 互換プロバイダーの API キーを接続できるようになりました。これらのオプションは、Anthropic、Microsoft Foundry、OpenAI、xAI とともに、サポートされている BYOK の選択肢に加わります。
- Responses API のサポート BYOK は Responses API を使用するモデルをサポートするようになりました。これにより、構造化された出力とより豊かなマルチモーダルインタラクションが可能になります。
- 最大コンテキストウィンドウを設定する機能 管理者は BYOK モデルの最大コンテキストウィンドウを定義でき、コスト、パフォーマンス、応答品質のバランスを取るのに役立ちます。
- より高速なインタラクションのためのストリーミング応答 接続されたモデルからのストリーミング出力により、Copilot は完了を待つのではなく、生成された応答を表示できます。

### Start using the new BYOK features today
- これらの新機能は、GitHub Enterprise および Business のお客様向けにパブリックプレビューで現在利用可能です。エンタープライズまたは組織の設定で LLM プロバイダーの API キーを接続し、Copilot Chat とサポートされている IDE でモデルの使用を開始してください。詳細については、BYOK ドキュメントをご覧ください。

### Help us shape the future
- これはまだ始まりに過ぎず、あなたのフィードバックが次に来るものを導きます。GitHub Community 内でディスカッションに参加してフィードバックを共有し、他の開発者とつながってください。

## Key Changes
- これらの新機能は、GitHub Enterprise および Business のお客様向けにパブリックプレビューで現在利用可能です。エンタープライズまたは組織の設定で LLM プロバイダーの API キーを接続し、Copilot Chat とサポートされている IDE でモデルの使用を開始してください。詳細については、BYOK ドキュメントをご覧ください。

## Impact / Who’s Affected
- Start using the new BYOK features today これらの新機能は、GitHub Enterprise および Business のお客様向けにパブリックプレビューで現在利用可能です。

## Insights (derived from article language)
- 詳細については、BYOK ドキュメントをご覧ください。

## Article Content (cleaned)
GitHub Copilot の Bring your own key (BYOK) が、追加の API、新しい設定オプション、より多くのプロバイダー統合をサポートするようになりました。


このアップデートにより、エンタープライズは Responses API を使用するモデルに接続し、モデルインタラクションの最大コンテキストウィンドウを設定し、ストリーミングを有効にし、拡張されたサポート対象 LLM プロバイダーのリストから選択できます。


### [What's new](#whats-new)


**新しいプロバイダーオプション**  

AWS Bedrock、Google AI Studio、およびあらゆる OpenAI 互換プロバイダーの API キーを接続できるようになりました。これらのオプションは、Anthropic、Microsoft Foundry、OpenAI、xAI とともに、サポートされている BYOK の選択肢に加わります。


**Responses API のサポート**  

BYOK は Responses API を使用するモデルをサポートするようになりました。これにより、構造化された出力とより豊かなマルチモーダルインタラクションが可能になります。


**最大コンテキストウィンドウを設定する機能**  

管理者は BYOK モデルの最大コンテキストウィンドウを定義でき、コスト、パフォーマンス、応答品質のバランスを取るのに役立ちます。


**より高速なインタラクションのためのストリーミング応答**  

接続されたモデルからのストリーミング出力により、Copilot は完了を待つのではなく、生成された応答を表示できます。


### [Start using the new BYOK features today](#start-using-the-new-byok-features-today)


これらの新機能は、GitHub Enterprise および Business のお客様向けにパブリックプレビューで現在利用可能です。エンタープライズまたは組織の設定で LLM プロバイダーの API キーを接続し、Copilot Chat とサポートされている IDE でモデルの使用を開始してください。詳細については、[BYOK ドキュメント](https://docs.github.com/copilot/how-tos/administer-copilot/manage-for-enterprise/use-your-own-api-keys) をご覧ください。


### [Help us shape the future](#help-us-shape-the-future)


これはまだ始まりに過ぎず、あなたのフィードバックが次に来るものを導きます。[GitHub Community](https://github.com/orgs/community/discussions/184350) 内でディスカッションに参加してフィードバックを共有し、他の開発者とつながってください。
