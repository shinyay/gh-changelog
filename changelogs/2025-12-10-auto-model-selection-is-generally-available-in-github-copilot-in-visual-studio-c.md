---
title: "Auto model selection is generally available in GitHub Copilot in Visual Studio Code"
date: "2025-12-10"
type: "new releases"
labels: ["copilot"]
author: "Allison"
source_url: "https://github.blog/changelog/2025-12-10-auto-model-selection-is-generally-available-in-github-copilot-in-visual-studio-code"
fetched_at: "2026-02-03T14:50:54.988574Z"
---

# Auto model selection is generally available in GitHub Copilot in Visual Studio Code

## Overview
GitHub Copilot auto model selection is now generally available in Visual Studio Code for all Copilot plans. With auto, Copilot chooses a model on your behalf based on current model availability.

## Detailed Explanation
### Overview
- GitHub Copilot auto model selection is now generally available in Visual Studio Code for all Copilot plans. With auto, Copilot chooses a model on your behalf based on current model availability.

### How it works
- Auto is dynamic, routing to models based on real-time availability. It provides you with the same access to your favorite models while mitigating rate limits. Auto routes to models like GPT-5.1-Codex-Max, GPT-5 mini, GPT-4.1, Sonnet 4.5, and Haiku 4.5 based on your plan and policies. The models auto will route to will change over time.
- Transparency : You can see which model was used by hovering over the model response.
- Stay in control : Switch between auto and any specific model at any time.
- Respects your policies : Auto honors all user and administrator model settings.

### Premium request use
- Premium request use for auto is billed based on the model it selects, which is currently limited to the models with 0x to 1x multipliers listed above. All paid subscribers get a 10% discount on the model multiplier when using auto (e.g., when auto uses a model that has a 1x multiplier, you will draw down 0.9 premium requests instead of 1).

### Where we’re headed
- Today, auto routes you to readily available, high quality models on your behalf.
- Soon, auto will become even more intelligent, gaining enhanced capabilities that allow Copilot to select the most appropriate model for your task, matching the model to the complexity level of your request.
- Questions or feedback? Join the Community discussion to share your thoughts.

## Impact / Who’s Affected
- GitHub Copilot auto model selection is now generally available in Visual Studio Code for all Copilot plans.
- Premium request use Premium request use for auto is billed based on the model it selects, which is currently limited to the models with 0x to 1x multipliers listed above.

## Caveats / Limitations
- Premium request use Premium request use for auto is billed based on the model it selects, which is currently limited to the models with 0x to 1x multipliers listed above.

## Article Content (cleaned)
[GitHub Copilot auto model selection](https://docs.github.com/copilot/concepts/auto-model-selection) is now generally available in Visual Studio Code for all Copilot plans. With auto, Copilot chooses a model on your behalf based on current model availability.


### [How it works](#how-it-works)


Auto is dynamic, routing to models based on real\-time availability. It provides you with the same access to your favorite models while mitigating rate limits. Auto routes to models like GPT\-5\.1\-Codex\-Max, GPT\-5 mini, GPT\-4\.1, Sonnet 4\.5, and Haiku 4\.5 based on your plan and policies. The models auto will route to will change over time.


* **Transparency**: You can see which model was used by hovering over the model response.
* **Stay in control**: Switch between auto and any specific model at any time.
* **Respects your policies**: Auto honors all user and administrator model settings.


## [Premium request use](#premium-request-use)


Premium request use for auto is billed based on the model it selects, which is currently limited to the [models with 0x to 1x multipliers](https://docs.github.com/copilot/concepts/billing/copilot-requests#model-multipliers) listed above. All paid subscribers get a 10% discount on the model multiplier when using auto (e.g., when auto uses a model that has a 1x multiplier, you will draw down 0\.9 premium requests instead of 1\).


## [Where we’re headed](#where-were-headed)


Today, auto routes you to readily available, high quality models on your behalf.


Soon, auto will become even more intelligent, gaining enhanced capabilities that allow Copilot to select the most appropriate model for your task, matching the model to the complexity level of your request.


Questions or feedback? Join the [Community discussion](https://github.com/orgs/community/discussions/categories/copilot-conversations) to share your thoughts.
